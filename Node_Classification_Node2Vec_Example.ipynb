{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Money Mule detection using Neo4j and Scikit-Learn/Tensorflow\n",
    "\n",
    "## Dataset\n",
    "Paysim is an approach using an agent-based model and some anonymized, aggregate transactional data from a real mobile money network operator to create synthetic financial data sets academics and hackers can use for exploring ways to detect fraudulent behavior.\n",
    "\n",
    "More info here: https://www.sisu.io/posts/paysim/\n",
    "\n",
    "https://www.kaggle.com/kartik2112/fraud-detection-on-paysim-dataset\n",
    "\n",
    "## Mules\n",
    "\n",
    "Money mules are defined as customers/clients that collude with fraudsters and facilitate moving money out of the network. Some of the typical activities of money mules are lending their credentials to fraudsters, send money to fraudsters in untreaceable amounts over a period of time, receive money from fraudsters and move money out of network etc.\n",
    "\n",
    "In this dataset, some clients are labelled as mules. Our task is to train supervised ML classification models using these labelled examples and detect if there are any mules among unlabelled clients in the dataset. \n",
    "\n",
    "## What we do\n",
    "- We will use Neo4j to load the data into a graph. \n",
    "- Preprocess the data to generate additional topological features\n",
    "- Generate graph embeddings using Neo4j GDS library \n",
    "- Train a supervised classification model in Neo4j GDS library\n",
    "- Train a supervised classification model using Keras/Tensorflow\n",
    "\n",
    "## Why Graphs and Graph Embeddings\n",
    "\n",
    "Detecting mules using abstract features such as transaction amounts, type of transactions, historical fradulent transactions ets is not effective and leads to a lot of false positives. Mules by definition are clients that collude fraudsters. There are no labelled fraudsters in the dataset. \n",
    "\n",
    "Here we need a method to generate a vector representation for every client based on their relationship to other clients and specifically with the clients that have potential to commit fraud. Hence, we need a graph datastructure and algorithms to generate topological features for training a classification model.\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "- Load Paysim dataset into Neo4j\n",
    "- Preprocess the dataset \n",
    "  - add class labels to mule examples\n",
    "  - generate additional relationships to add more context\n",
    "  - build additional graphy features on client nodes \n",
    "- Generate Client embeddings using\n",
    "  - Node2Vec (only relationships)\n",
    "- Generate Train/Test Splits\n",
    "- Train a Logistic Regression model in Neo4j GDS library\n",
    "    - Use k-fold cross validation to compute model metrics\n",
    "    - Test model performance of all models on the test graph\n",
    "    - Pick the best model and predict if there are any mules among unlabelled clients using the trained LR model\n",
    "- Get embeddings from Neo4j and train a neural net using Keras and compute model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/opt/anaconda3/bin/pip install neo4j\n",
    "#!/opt/anaconda3/bin/pip install tensorflow\n",
    "#!/opt/anaconda3/bin/pip install scikit-learn==0.24.2\n",
    "#!/opt/anaconda3/bin/pip install pandas\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase, exceptions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j interface\n",
    " \n",
    " Wrap neo4j python driver in Neo4j DB interface class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase, Query, unit_of_work\n",
    "class Neo4j():\n",
    "    \"\"\"\n",
    "    Neo4J DB Interface class\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        url = kwargs.get('url', 'bolt://localhost:7687/')\n",
    "        username = kwargs.get('username', 'neo4j')\n",
    "        password = kwargs.get('password', 'letmein')\n",
    "        database = kwargs.get('database', 'neo4j')\n",
    "        self.client = GraphDatabase.driver(url, auth=(username, password), database=database)\n",
    "        \n",
    "    @unit_of_work(timeout=1200)\n",
    "    def __run(self, tx, query, **kwargs):\n",
    "        if kwargs.get('data_frame'):\n",
    "            return pd.DataFrame([dict(record) for record in tx.run(query)])\n",
    "        result = [row for row in tx.run(query)]\n",
    "        return result\n",
    "    \n",
    "    def execute(self, query, **kwargs):\n",
    "        with self.client.session() as session:\n",
    "            tx = session.begin_transaction()\n",
    "            result = self.__run(tx, query, **kwargs)\n",
    "            tx.close()\n",
    "            return result\n",
    "        \n",
    "    def read(self, query, **kwargs):\n",
    "        with self.client.session() as session:\n",
    "            return session.read_transaction(self.__run, query, **kwargs)\n",
    "    \n",
    "    def write(self, query):\n",
    "        with self.client.session() as session:\n",
    "            return session.write_transaction(self.__run, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "url = 'neo4j+s://gds.neo4j.academy:443'\n",
    "username = 'neo4j'\n",
    "password = 'neo4j'\n",
    "database = 'paysimxxx'\n",
    "n = Neo4j(url=url, username=username, password=password, database=database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Add target property to identify Mules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"MATCH (c:Client) WHERE NOT c:Mule SET c.is_mule = 0;\"\"\"\n",
    "_ = n.write(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"MATCH (c:Mule) SET c.is_mule = 1;\"\"\"\n",
    "_ = n.write(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TRANSACTS_WITH` relationship \n",
    "- connect a pair of clients that send or receive money from others\n",
    "- Instead of using actual amount of transaction, assign transaction categories based on transaction amounts\n",
    "- Compute percentiles based on transaction amounts and assign transaction category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin transaction amounts into transaction categories\n",
    "q = \"\"\"\n",
    "    MATCH (t:Transfer) \n",
    "    WITH apoc.agg.statistics(t.amount, [0.1, 0.25, 0.5, 0.75]) as m\n",
    "    MATCH (t:Transfer) \n",
    "    WITH t, m, CASE \n",
    "        WHEN t.amount <= m.`0.1` THEN toFloat(1.0)\n",
    "        WHEN m.`0.1` <= t.amount <= m.`0.25` THEN toFloat(2.0)\n",
    "        WHEN m.`0.25` <= t.amount <= m.`0.5` THEN toFloat(3.0)\n",
    "        WHEN m.`0.5` <= t.amount <= m.`0.75` THEN toFloat(4.0)\n",
    "        WHEN t.amount > m.`0.75` THEN toFloat(5.0)\n",
    "        ELSE toFloat(0.0)\n",
    "    END AS cat\n",
    "    SET t.amountCategory = cat;\n",
    "    \"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TRANSACTS_WITH relationship with transaction category as weight o the relationship\n",
    "q = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"MATCH (c1:Client)-[:PERFORMED]->(t:Transfer)-[:TO]->(c2:Client)\n",
    "        RETURN c1, c2, t.amountCategory as txnCat\",\n",
    "    \"MERGE (c1) - [:TRANSACTS_WITH {txnCat: txnCat}] -> (c2)\",\n",
    "    {batchSize: 1000});\n",
    "    \"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fraud risk score\n",
    "- Compute fraud risk score for every client based on connections to previously identified fraudulent txns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    MATCH (c:Client)-[]->(t:Transaction) WHERE t.fraud=true\n",
    "    WITH count(t) as fraudtxns\n",
    "    WITH apoc.coll.max(collect(fraudtxns)) as maxNum\n",
    "    MATCH (c:Client)-[]->(t:Transaction) WHERE t.fraud=true\n",
    "    WITH c, maxNum, count(t) as fraudCount\n",
    "    SET  c.fraud_risk_score = toFloat(fraudCount) / maxNum;\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fraud_risk_score = 0 for all other clients\n",
    "q = \"\"\"\n",
    "    MATCH (c:Client) WHERE NOT exists(c.fraud_risk_score)\n",
    "    SET c.fraud_risk_score = 0.0\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Shared Identifiers Risk Score\n",
    "\n",
    "Our hypothesis is that Clients who share identifiers (Phone Number, Email Address and SSN) are most likely to commit fraud. We exepct the clients not sharing any identifiers. It is possible a phone number is shared between two clients but a shared SSN is definitely a red flag.\n",
    "\n",
    "**Examples**: \n",
    "- A client shares an email address with three other clients and a phone number with a different client and SSN with four clients.\n",
    "- A client only shares a phone number with another client\n",
    "- A clinet shares a SSN with three other clients\n",
    "- ...\n",
    "\n",
    "Compute **shared identifiers risk score** for all clients\n",
    "- Find patterns of shared identifiers and persisting a new relationhsip between clients\n",
    "- Find paiwise similarity between all clients that share identifiers \n",
    "- Use pairwise similarity score to compute weighted centrality score (**si_risk_score**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship to connect clients that share one or more than one of the identifiers like SSN, Email or Phone Number\n",
    "q = \"\"\"\n",
    "    MATCH (c1:Client)-[:HAS_EMAIL|:HAS_PHONE|:HAS_SSN] ->(n)<- [:HAS_EMAIL|:HAS_PHONE|:HAS_SSN]-(c2:Client)\n",
    "    WHERE c1.id<>c2.id\n",
    "    WITH c1, c2, count(*) as cnt\n",
    "    MERGE (c1) - [:SHARED_IDENTIFIERS {count: cnt}] -> (c2);\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project a graph to run similarity \n",
    "q = \"\"\"\n",
    "    CALL gds.graph.create('client_graph', \n",
    "    'Client',\n",
    "        {\n",
    "            SHARED_IDENTIFIERS:{\n",
    "                type: 'SHARED_IDENTIFIERS',\n",
    "                orientation:'NATURAL',\n",
    "                properties: 'count'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            readConcurrency: 4\n",
    "        }     \n",
    "    ) YIELD graphName, nodeCount, relationshipCount, createMillis;\n",
    "\"\"\"\n",
    "res = n.execute(q, **{'data_frame':True})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Weighted Node Similarity and mutate in-memory graph\n",
    "\n",
    "q = \"\"\"\n",
    "    CALL gds.nodeSimilarity.mutate('client_graph',\n",
    "        {\n",
    "            similarityCutoff: 0.05,\n",
    "            concurrency: 4,\n",
    "            mutateRelationshipType:'SIMILAR_TO',\n",
    "            mutateProperty:'score',\n",
    "            relationshipWeightProperty:'count'\n",
    "        }                   \n",
    "    )\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run weighted degree centrality to compute si_risk_score\n",
    "q = \"\"\"\n",
    "    CALL gds.degree.mutate('client_graph',\n",
    "        {\n",
    "            nodeLabels: ['Client'],\n",
    "            relationshipTypes:['SIMILAR_TO'],\n",
    "            relationshipWeightProperty: 'score',\n",
    "            mutateProperty: 'si_risk_score'\n",
    "        }                   \n",
    "    )\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shared identifiers risk scores to the database\n",
    "q = \"\"\"\n",
    "    CALL gds.graph.writeNodeProperties(\n",
    "      'client_graph',\n",
    "      ['si_risk_score'],\n",
    "      ['Client'],\n",
    "      { writeConcurrency: 4 }\n",
    "    );\n",
    "\"\"\"\n",
    "res = n.execute(q, **{'data_frame':True})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the in-memory graph\n",
    "q = \"\"\" CALL gds.graph.drop('client_graph')\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to fix convert the data type of risk scores from long to floats\n",
    "q = \"\"\"MATCH (c:Client) SET c.fraud_risk_score  = toFloat(c.fraud_risk_score);\"\"\"\n",
    "_ = n.write(q)\n",
    "q = \"\"\"MATCH (c:Client) SET c.si_risk_score  = toFloat(c.si_risk_score);\"\"\"\n",
    "_ = n.write(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Update `TRANSACTS_WITH` relationship\n",
    "\n",
    "- Update the weight on the relationship with a composite score of transaction category + fraud_risk_score + si_risk_score\n",
    "- This gives higher weight to relationships with known and suspected fraudsters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"MATCH (c1:Client) - [t:TRANSACTS_WITH] -> (c2:Client) RETURN c1, c2, t\",\n",
    "        \"SET t.weight = t.txnCat + c1.fraud_risk_score + c1.si_risk_score + c2.fraud_risk_score + c2.si_risk_score\",\n",
    "        {batchSize:100}\n",
    "    );\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised ML: Train/Test Split\n",
    "\n",
    "Label nodes to split Clients into Train and Test data\n",
    "\n",
    "- Randomly splitting the dataset (80/20)\n",
    "- Add new class labels to differentiate training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick 80% of clients and label them as training data\n",
    "q = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"MATCH (c:Client) WITH collect(ID(c)) as clients \n",
    "        RETURN apoc.coll.randomItems(clients, toInteger(0.8 * size(clients))) as trainClients\", \n",
    "    \"UNWIND trainClients as trainClient \n",
    "        MATCH (c:Client) WHERE ID(c) = trainClient \n",
    "        SET c.is_train_data = 1\", {batchSize: 10000});\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the remianing clients as test data\n",
    "q = \"\"\"\n",
    "MATCH (c:Client) WHERE NOT exists(c.is_train_data)\n",
    "SET c.is_train_data = 0;\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of mules in train data\n",
    "\n",
    "q = \"\"\"\n",
    "MATCH (c:Client) WHERE c.is_mule = 1 and c.is_train_data = 1\n",
    "return count(c) as Mules;\n",
    "\"\"\"\n",
    "res = n.read(q, **{'data_frame': True})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of mules in test data\n",
    "\n",
    "q = \"\"\"\n",
    "MATCH (c:Client) WHERE c.is_mule = 1 and c.is_train_data = 0\n",
    "return count(c) as Mules;\n",
    "\"\"\"\n",
    "res = n.read(q, **{'data_frame': True})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Embeddings\n",
    "\n",
    "### Node2Vec\n",
    "    - Node2Vec works on weighted graphs but doesn't take into account the node properties\n",
    "    - Node2Vec is transductive; Embeddings have to be recomputed when the underlying data changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project in-memory graph with newly added relationships and node properties\n",
    "q = \"\"\"\n",
    "    CALL gds.graph.create('mule_graph', \n",
    "        {\n",
    "            Client:{\n",
    "                label:'Client',\n",
    "                properties:{\n",
    "                    is_mule:{property:'is_mule',defaultValue:0},\n",
    "                    fraud_risk_score:{property:'fraud_risk_score',defaultValue:0.0},\n",
    "                    si_risk_score:{property: 'si_risk_score', defaultValue: 0.0},\n",
    "                    is_train_data:{property:'is_train_data',defaultValue:0}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            TRANSACTS_WITH:{\n",
    "                type: 'TRANSACTS_WITH',\n",
    "                orientation:'UNDIRECTED',\n",
    "                properties: 'weight',\n",
    "                aggregation:'SUM'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "          readConcurrency: 4\n",
    "        }\n",
    "    ) YIELD graphName, nodeCount, relationshipCount, createMillis;\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding using Node2Vec \n",
    "\n",
    "q = \"\"\"\n",
    "    CALL gds.beta.node2vec.mutate('mule_graph', \n",
    "        {\n",
    "         embeddingDimension: 256, \n",
    "         walkLength:16,\n",
    "         walksPerNode: 64,\n",
    "         returnFactor: 0.5,\n",
    "         inOutFactor: 1.5,\n",
    "         iterations: 20,\n",
    "         mutateProperty:'n2v_embedding',\n",
    "         concurrency:4,\n",
    "         relationshipWeightProperty: 'weight'\n",
    "        }\n",
    "    );\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Node embeddings back to the database\n",
    "q = \"\"\"\n",
    "    CALL gds.graph.writeNodeProperties(\n",
    "      'mule_graph',\n",
    "      ['n2v_embedding'],\n",
    "      ['Client'],\n",
    "       {\n",
    "         writeConcurrency: 4\n",
    "       }\n",
    "    );\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised ML in Neo4j\n",
    "\n",
    "- Create a subgraph with train data\n",
    "- Train a logistic regression model\n",
    "- Save the model into model catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subgraph by filtering on `is_train_data` label\n",
    "q = \"\"\"\n",
    "    CALL gds.beta.graph.create.subgraph('mule_train_graph', 'mule_graph', 'n:Client AND n.is_train_data = 1', '*')\n",
    "    YIELD graphName, fromGraphName, nodeCount, relationshipCount;\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "q = \"\"\"\n",
    "    CALL gds.alpha.ml.nodeClassification.train('mule_train_graph', {\n",
    "       nodeLabels: ['Client'],\n",
    "       modelName: 'mule_model_n2v',\n",
    "       featureProperties: ['n2v_embedding'], \n",
    "       targetProperty: 'is_mule', \n",
    "       metrics: ['F1_WEIGHTED', 'PRECISION(class=*)', 'RECALL(class=*)', 'F1(class=*)'], \n",
    "       holdoutFraction: 0.2, \n",
    "       validationFolds: 3, \n",
    "       randomSeed: 2,\n",
    "       params: [\n",
    "        {penalty: 0.0625},\n",
    "        {penalty: 0.5},\n",
    "        {penalty: 1.0}\n",
    "       ]\n",
    "    }) YIELD modelInfo\n",
    "    RETURN\n",
    "    {penalty: modelInfo.bestParameters.penalty} AS winningModel,\n",
    "    modelInfo.metrics.F1_WEIGHTED.outerTrain AS F1_WEIGHTED_TRAIN,\n",
    "    modelInfo.metrics.F1_WEIGHTED.test AS F1_WEIGHTED_TEST,\n",
    "    modelInfo.metrics.F1_class_0.test AS F1_TEST_CLASS_0,\n",
    "    modelInfo.metrics.F1_class_1.test AS F1_TEST_CLASS_1,\n",
    "    modelInfo.metrics.PRECISION_class_0.test AS PRECISION_TEST_CLASS_0,\n",
    "    modelInfo.metrics.PRECISION_class_1.test AS PRECISION_TEST_CLASS_1,\n",
    "    modelInfo.metrics.RECALL_class_0.test AS RECALL_TEST_CLASS_0,\n",
    "    modelInfo.metrics.RECALL_class_1.test AS RECALL_TEST_CLASS_1;\n",
    "\"\"\"\n",
    "res = n.execute(q, **{'data_frame':True})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test Graph\n",
    "\n",
    "- Predict mule labels and probability on test graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    CALL gds.beta.graph.create.subgraph('mule_test_graph', 'mule_graph', 'n:Client AND n.is_train_data = 0', '*')\n",
    "    YIELD graphName, fromGraphName, nodeCount, relationshipCount;\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    CALL gds.alpha.ml.nodeClassification.predict.mutate('mule_test_graph', {\n",
    "      nodeLabels: ['Client'],\n",
    "      modelName: 'mule_model_n2v',\n",
    "      mutateProperty: 'predicted_mule_n2v',\n",
    "      predictedProbabilityProperty: 'predicted_mule_probability_n2v'\n",
    "    });\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write predicted labels back to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    CALL gds.graph.writeNodeProperties(\n",
    "      'mule_test_graph',\n",
    "      ['predicted_mule_n2v', 'predicted_mule_probability_n2v'],\n",
    "      ['Client']\n",
    "    );\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    WITH [\n",
    "      { model: 'Node2Vec', label: 'predicted_mule_n2v' }\n",
    "      ] AS models\n",
    "    UNWIND models AS model\n",
    "    WITH model.model AS m, model.label AS label\n",
    "    MATCH (c:Client) WHERE c[label] = 0 AND c.is_mule = 0\n",
    "    WITH m, label, count(c) AS TP\n",
    "    OPTIONAL MATCH (c:Client) WHERE c[label] = 0 AND c.is_mule = 1\n",
    "    WITH m, label, TP, count(c) AS FN\n",
    "    OPTIONAL MATCH (c:Client) WHERE c[label] = 1 AND c.is_mule = 0\n",
    "    WITH m, label, TP, FN, count(c) AS FP\n",
    "    OPTIONAL MATCH (c:Client) WHERE c[label] = 1 AND c.is_mule = 1\n",
    "    WITH m, TP, FN, FP, count(c) AS TN\n",
    "    RETURN m, TP, FP, FN, TN\n",
    "\"\"\"\n",
    "res = n.read(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.array([res[0][k] for k, v in res[0].items() if k != 'm']).reshape(2,2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array([0,1]))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn/Tensorflow\n",
    "\n",
    "- Get embeddings from Neo4j\n",
    "- Train a neural network on train data\n",
    "- Test the performance on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Embeddings from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "MATCH (c:Client)\n",
    "RETURN c.id AS ClientId, \n",
    "c.n2v_embedding AS Embedding,\n",
    "c.is_mule as Mule,\n",
    "c.is_train_data as Train_Test_Split;\n",
    "\"\"\"\n",
    "df = n.execute(q, **{'data_frame':True})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test data\n",
    "train_df = df[df.Train_Test_Split == 1]\n",
    "test_df = df[df.Train_Test_Split == 0]\n",
    "\n",
    "X_train = np.vstack([row for row in train_df.Embedding.values])\n",
    "Y_train = train_df.Mule.values\n",
    "\n",
    "X_test = np.vstack([row for row in test_df.Embedding.values])\n",
    "Y_test = test_df.Mule.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim=256):\n",
    "    # structure model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim, input_dim=input_dim, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train and Cross validate using scikit-learn Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=100, batch_size=250, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "results\n",
    "#print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = estimator.predict(X_test)\n",
    "Y_pred = np.hstack([i for i in Y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, list(Y_pred), labels=estimator.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=estimator.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop in-memory graphs\n",
    "q = \"\"\"\n",
    "    CALL gds.graph.list()\n",
    "    YIELD graphName AS namedGraph, database\n",
    "    WITH namedGraph where database='{database}'\n",
    "    CALL gds.graph.drop(namedGraph)\n",
    "    YIELD graphName\n",
    "    RETURN graphName;\n",
    "\"\"\".format(database=database)\n",
    "res = n.execute(q)\n",
    "print(res)\n",
    "\n",
    "\n",
    "# Delete models\n",
    "q = \"\"\"\n",
    "    CALL gds.beta.model.list()\n",
    "    YIELD modelInfo\n",
    "    WITH modelInfo.modelName as m\n",
    "    CALL gds.beta.model.drop(m)\n",
    "    YIELD modelInfo\n",
    "    RETURN modelInfo.modelName;\n",
    "\"\"\"\n",
    "res = n.execute(q)\n",
    "print(res)\n",
    "                         \n",
    "# Delete relationships\n",
    "q = \"\"\"\n",
    "UNWIND ['SHARED_IDENTIFIERS', 'TRANSACTS_WITH'] AS rel\n",
    "MATCH ()-[r]->() WHERE type(r) = rel\n",
    "DELETE r;\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)\n",
    "\n",
    "# Delete properties on clients\n",
    "q = \"\"\"\n",
    "MATCH (c:Client) \n",
    "REMOVE c.is_mule, \n",
    "c.is_train_data, \n",
    "c.fraud_risk_score, \n",
    "c.si_risk_score, \n",
    "c.n2v_embedding,\n",
    "c.predicted_mule_n2v,\n",
    "c.predicted_mule_probability_n2v,\n",
    "c.predicted_mule,\n",
    "c.predicted_mule_probability;\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)\n",
    "\n",
    "# Delete properties on Transfer nodes\n",
    "q = \"\"\"\n",
    "MATCH (t:Transfer) REMOVE t.amountCategory;\n",
    "\"\"\"\n",
    "res = n.write(q)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
